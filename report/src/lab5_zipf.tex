\section{Закон Ципфа}

\subsection{Теоретические основы}

\textbf{Закон Ципфа} утверждает, что частота слова в корпусе текстов обратно пропорциональна его рангу:

\[ f(r) = \frac{C}{r} \]

где $f(r)$ --- частота термина с рангом $r$, $C$ --- константа, зависящая от корпуса.

В логарифмической шкале закон Ципфа представляет собой прямую линию с наклоном $-1$:

\[ \log f(r) = \log C - \log r \]

Более точное приближение даёт обобщённый закон Ципфа--Мандельброта:
\[ f(r) = \frac{C}{(r + b)^a} \]
где $a$ и $b$ --- параметры, подбираемые по реальным данным.

\subsection{Реализация анализатора}

Класс \texttt{ZipfAnalyzer} реализован на C++ и выполняет следующие функции:
\begin{enumerate}
    \item Подсчёт частот всех терминов после стемминга с использованием собственной хеш-таблицы \texttt{StringMap}
    \item Сортировка терминов по убыванию частоты (сортировка слиянием, $O(N \log N)$)
    \item Присвоение рангов
    \item Передача данных через HTTP API для визуализации во фронтенде
\end{enumerate}

Данные для построения графиков передаются через API-эндпоинт \texttt{/api/zipf}, который возвращает JSON с рангами, частотами и теоретическими предсказаниями. Визуализация выполняется в веб-интерфейсе с помощью библиотеки Chart.js.

\subsection{Результаты анализа}

\begin{table}[H]
\centering
\begin{tabular}{lr}
\toprule
\textbf{Параметр} & \textbf{Значение} \\
\midrule
Общее число терминов (после стемминга) & $\sim$50\,000\,000 \\
Уникальных терминов & $\sim$480\,000 \\
Hapax legomena (частота = 1) & $\sim$40--50\% терминов \\
Редкие термины (частота $\leq$ 5) & $\sim$70--80\% терминов \\
Топ-10 терминов покрывают & $\sim$15--20\% вхождений \\
Топ-100 терминов покрывают & $\sim$35--40\% вхождений \\
\bottomrule
\end{tabular}
\caption{Статистика распределения терминов}
\end{table}

\subsection{Визуализация}

% TODO: Вставить скриншот графика закона Ципфа из веб-интерфейса
\begin{center}
\textit{[Место для скриншота графика закона Ципфа из веб-интерфейса]}

% Раскомментировать после добавления изображения:
% \begin{figure}[H]
% \centering
% \includegraphics[width=\textwidth]{images/zipf_chart.png}
% \caption{Распределение терминов по закону Ципфа (log-log шкала)}
% \label{fig:zipf}
% \end{figure}
\end{center}

На графике в логарифмической шкале отображаются:
\begin{itemize}
    \item \textbf{Реальные данные}: логарифм частоты от логарифма ранга для каждого термина
    \item \textbf{Теоретическая кривая Ципфа}: прямая $\log f = \log C - \log r$
\end{itemize}

\subsection{Причины расхождения с теоретической моделью}

Реальное распределение отклоняется от идеального закона Ципфа:

\begin{enumerate}
    \item \textbf{Голова распределения}: самые частые слова (стоп-слова, предлоги) встречаются чаще, чем предсказывает закон. Это объясняется тем, что служебные слова используются в каждом предложении.
    
    \item \textbf{Хвост распределения}: редкие термины (имена авторов, названия произведений) более многочисленны, чем предсказано. Литературный корпус содержит множество имён собственных и уникальных названий.
    
    \item \textbf{Тематическая специфика}: корпус по литературе содержит повторяющуюся терминологию (<<роман>>, <<автор>>, <<произведение>>), что деформирует среднюю часть распределения.
    
    \item \textbf{Эффект стемминга}: объединение словоформ увеличивает частоты базовых форм и смещает распределение.
    
    \item \textbf{Размер корпуса}: закон Ципфа лучше проявляется на больших корпусах; при 35\,000 документов наблюдаются отклонения.
    
    \item \textbf{Предварительная обработка}: фильтрация коротких токенов и чисел влияет на хвост распределения.
\end{enumerate}

\subsection{Журнал выполнения задания}

При реализации анализатора закона Ципфа были выявлены следующие проблемы и их решения:

\begin{enumerate}
    \item \textbf{Эффективный подсчёт терминов для большого словаря}: При обработке корпуса из ~50 миллионов токенов стандартные структуры данных C++ (\texttt{std::unordered\_map}) показали недостаточную производительность из-за частых аллокаций памяти при вставке новых элементов. Решение: использование собственной хеш-таблицы \texttt{StringMap} с предварительным резервированием памяти и оптимизированной хеш-функцией для строк UTF-8.
    
    \item \textbf{Выбор библиотеки для визуализации}: Изначально планировалось использовать серверную генерацию графиков (например, matplotlib через Python), но это требовало дополнительной инфраструктуры и замедляло отображение результатов. Решение: передача данных через HTTP API в формате JSON и визуализация на клиенте с помощью Chart.js, что обеспечивает интерактивность и быструю загрузку.
    
    \item \textbf{Обработка длинного хвоста распределения}: Распределение содержит ~480\,000 уникальных терминов, из которых ~70--80\% встречаются редко (частота $\leq$ 5). Отображение всех точек на графике создавало визуальный шум и затрудняло анализ. Решение: агрегация редких терминов по диапазонам рангов и отображение только репрезентативных точек для хвоста распределения.
    
    \item \textbf{Память при сортировке}: Сортировка ~480\,000 пар (термин, частота) требовала значительной памяти. Использование сортировки слиянием (merge sort) вместо быстрой сортировки (quicksort) обеспечило стабильность и предсказуемое потребление памяти, хотя и с небольшим замедлением.
\end{enumerate}

\subsection{Выводы}

Анализ распределения терминов в корпусе подтверждает применимость закона Ципфа к реальным текстовым данным, хотя наблюдаются систематические отклонения от теоретической модели.

\textbf{Подтверждение закона Ципфа:}
Распределение частот терминов в целом следует закону Ципфа: наиболее частые слова (стоп-слова, предлоги) занимают первые ранги, а редкие термины образуют длинный хвост. Логарифмический график показывает линейную зависимость в средней части распределения, что соответствует теоретическим предсказаниям.

\textbf{Систематические отклонения:}
\begin{itemize}
    \item \textbf{Голова распределения}: Превышение частот для топ-10--20 терминов объясняется тематической спецификой корпуса (термины <<роман>>, <<автор>>, <<произведение>> встречаются в каждой статье) и эффектом стемминга, объединяющего словоформы.
    
    \item \textbf{Хвост распределения}: Большое количество редких терминов (hapax legomena составляют ~40--50\%) характерно для литературного корпуса, содержащего множество имён собственных, названий произведений и специализированной терминологии.
\end{itemize}

\textbf{Влияние на поисковую систему:}
\begin{itemize}
    \item Высокая концентрация частот в топ-100 терминах (~35--40\% вхождений) означает, что инвертированный индекс для этих терминов будет очень большим, что влияет на производительность поиска
    \item Длинный хвост редких терминов требует эффективной структуры данных для хранения постинговых списков с низкой частотой
    \item Закон Ципфа подтверждает необходимость стоп-слов для фильтрации самых частых, но малосодержательных терминов
\end{itemize}

\textbf{Недостатки текущего анализа:}
\begin{itemize}
    \item Анализ выполнен только для стеммированных терминов --- распределение исходных словоформ может отличаться
    \item Не учитывается влияние длины документа на частоту терминов (длинные статьи могут искажать распределение)
    \item Отсутствует сравнение с другими корпусами для выявления специфики литературной тематики
\end{itemize}

\textbf{Возможные улучшения:}
\begin{itemize}
    \item Сравнение распределения до и после стемминга для оценки влияния нормализации
    \item Анализ распределения по частям речи (существительные, прилагательные, глаголы) для более глубокого понимания структуры корпуса
    \item Применение обобщённого закона Ципфа--Мандельброта для более точного моделирования отклонений
    \item Визуализация распределения для отдельных категорий корпуса (например, только статьи об авторах или только о произведениях)
\end{itemize}

\pagebreak
